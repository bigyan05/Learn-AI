{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773fe67-a45c-4d31-99a7-e9a11af5ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065307e-5c51-4c1c-bce4-ab5229cff506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def99a9a-6c92-49c0-99d7-1a556af86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
    "# cache_dir indicates where to download data.  \".\" means current directory\n",
    "# untar true will unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b0242-0da2-465c-b9bd-f688e4d92bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abd92f-20d1-4a97-9dbf-7db54195b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib  \n",
    "\n",
    "data_dir = pathlib.Path(data_dir)  # Convert 'data_dir' to a Path object for easier path handling\n",
    "data_dir  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492d275-779f-4611-86ad-c020fcb39f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14bffb-135b-4126-986e-6b5105eb2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76de81-45d0-49a5-9eb1-24c6c89958eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = list(data_dir.glob('roses/*'))\n",
    "roses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023326ae-f768-40da-870d-1fc5d8318a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(roses[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af9e13-8366-4657-9f00-e7c0cace585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tulips = list(data_dir.glob('tulips/*'))\n",
    "PIL.Image.open(str(tulips[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360903d-a16c-4230-bf3a-d309c0192a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'daisy': list(data_dir.glob('daisy/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
    "    'tulips': list(data_dir.glob('tulips/*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416aefff-360d-4ec5-ab5e-b5a8084d3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers': 3,\n",
    "    'tulips': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29081dd-94d1-4180-8e67-811b692017df",
   "metadata": {},
   "source": [
    "### Using opencv to read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1c3c2-f646-487f-8a02-9516f7e875fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []  # Initialize empty lists for images (X) and their labels (y)\n",
    "\n",
    "# Loop through each flower category and its image paths\n",
    "for flower_name, images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))  # Read the image using OpenCV\n",
    "        resized_img = cv2.resize(img, (180, 180))  # Resize image to 180x180 pixels\n",
    "        X.append(resized_img)  # Add the processed image to the list\n",
    "        y.append(flowers_labels_dict[flower_name])  # Add the corresponding label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11a9b5-4fb8-4afd-b768-b9f20ad8e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2e8de-1379-4997-9197-1dd9373ce19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5f650-0b4e-43e8-998c-83c642bf9c4c",
   "metadata": {},
   "source": [
    "### Scaling Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae71cd-16b9-47c9-97a2-49b5b81bad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f6e9f-ff3b-4f8a-9f46-ac88c6af3ef0",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed7388-b282-433e-bc1a-973c1307dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "model.fit(X_train, y_train, epochs=30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0a339-cdd6-4cc7-9cee-a5009b8463f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cbd7ae-b1db-478c-aa95-bdd808c6bd8a",
   "metadata": {},
   "source": [
    "Training accuracy is .99 and testing is .63 so, clearly is an overfit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5bb96-9c48-4de9-b52d-6ecef8a1d749",
   "metadata": {},
   "source": [
    "### Trying to check prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249e0f4-6562-4b69-b4b1-37fc6cd2505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33aa19-e983-4a74-9996-633e04d0721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.nn.softmax(predictions[0])\n",
    "print(np.argmax(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba68799-60d8-4fae-9544-4203ab05b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439253a-9611-4fce-be54-f2b381b13bcd",
   "metadata": {},
   "source": [
    "Seems like it did predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28690e2-5d7e-4df1-be3d-e29f97aa4aab",
   "metadata": {},
   "source": [
    "## Performing Data Augmentation now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dacdab-8db1-41a6-adff-cfa88222e6a1",
   "metadata": {},
   "source": [
    "Was crashing from here before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6fdc6f-5585-494d-bf86-26641dcdb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = keras.Sequential([layers.RandomZoom(0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c244b792-6ba9-48db-a65e-361e534a654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    # Randomly flip images horizontally during training\n",
    "    layers.RandomFlip(mode=\"horizontal\", seed=None, input_shape=(180, 180, 3)),\n",
    "\n",
    "    # Randomly rotate images by up to 10%\n",
    "    layers.RandomRotation(0.1),\n",
    "\n",
    "    # Randomly zoom in on images by up to 10%\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d5bf0-9ee2-41aa-9b3a-53800153c06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
